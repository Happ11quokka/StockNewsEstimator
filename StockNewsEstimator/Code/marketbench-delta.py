import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import os
from scipy import stats

# í•œê¸€ í°íŠ¸ ì„¤ì • (matplotlib)
plt.rc('font', family='AppleGothic')
plt.rcParams['axes.unicode_minus'] = False


def calculate_equal_weighted_benchmark(df, category_col='Sector'):
    """
    ê° ì¹´í…Œê³ ë¦¬ë³„ ë™ì¼ê°€ì¤‘ ë²¤ì¹˜ë§ˆí¬ ìˆ˜ìµë¥  ê³„ì‚°
    """
    benchmark_results = {}

    # ì „ì²´ ë²¤ì¹˜ë§ˆí¬
    all_benchmark = calculate_category_benchmark(df)
    benchmark_results['ì „ì²´'] = all_benchmark

    # ì¹´í…Œê³ ë¦¬ë³„ ë²¤ì¹˜ë§ˆí¬
    categories = df[category_col].unique()
    for category in categories:
        category_df = df[df[category_col] == category].copy()
        if len(category_df) > 0:
            category_benchmark = calculate_category_benchmark(category_df)
            benchmark_results[category] = category_benchmark

    return benchmark_results


def calculate_category_benchmark(df):
    """
    íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ 'ì‹œì¥ ì „ì²´ í‰ê· ' ë™ì¼ê°€ì¤‘ ë²¤ì¹˜ë§ˆí¬ ìˆ˜ìµë¥  ê³„ì‚°
    (long/short í¬ì§€ì…˜ ìœ ë¬´ì— ê´€ê³„ì—†ì´ ëª¨ë“  ì¢…ëª© í¬í•¨)
    """
    # current_dateë¥¼ datetimeìœ¼ë¡œ ë³€í™˜
    df['current_date'] = pd.to_datetime(df['current_date'])

    # ê° ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”
    grouped = df.groupby('current_date')

    daily_benchmark = []

    for date, group in grouped:
        # ê° ì¢…ëª©ì˜ í‰ê·  ìˆ˜ìµë¥ : (long_return + short_return) / 2
        # í¬ì§€ì…˜ ìœ ë¬´ì— ê´€ê³„ì—†ì´ ëª¨ë“  ì¢…ëª©ì„ í¬í•¨
        group['avg_return'] = (group['long_return'] +
                               group['short_return']) / 2

        # ëª¨ë“  ì¢…ëª©ì˜ í‰ê·  ìˆ˜ìµë¥ ì„ ë™ì¼ê°€ì¤‘ìœ¼ë¡œ ê³„ì‚°
        all_returns = group['avg_return']
        benchmark_return = all_returns.mean() if not all_returns.empty else 0

        daily_benchmark.append({
            'current_date': date,
            'benchmark_return': benchmark_return,
            'n_stocks': len(all_returns)  # ëª¨ë“  ì¢…ëª© ìˆ˜
        })

    # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
    benchmark_df = pd.DataFrame(daily_benchmark).set_index('current_date')

    # ëˆ„ì  ìˆ˜ìµë¥  ê³„ì‚°
    benchmark_df['cumulative_return'] = (
        1 + benchmark_df['benchmark_return']).cumprod()

    return benchmark_df


def calculate_delta_neutral_by_category_with_benchmark(df, category_col='ê·œëª¨êµ¬ë¶„'):
    """
    ì¹´í…Œê³ ë¦¬ë³„ ë¸íƒ€-ë‰´íŠ¸ëŸ´ ë°©ì‹ìœ¼ë¡œ ëˆ„ì  ìˆ˜ìµë¥  ê³„ì‚° (ë²¤ì¹˜ë§ˆí¬ í¬í•¨)
    """
    # current_dateë¥¼ datetimeìœ¼ë¡œ ë³€í™˜
    df['current_date'] = pd.to_datetime(df['current_date'])

    # ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ê³„ì‚°
    benchmark_results = calculate_equal_weighted_benchmark(df, category_col)

    # ì „ì²´ ê²°ê³¼ ì €ì¥
    all_results = {}

    # 1. ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ ê³„ì‚°
    all_cum, all_daily = calculate_delta_neutral_returns(df)
    all_results['ì „ì²´'] = {
        'cumulative': all_cum,
        'daily': all_daily,
        'benchmark': benchmark_results['ì „ì²´'],
        'metrics': calculate_performance_metrics_with_benchmark(all_daily, benchmark_results['ì „ì²´'])
    }

    # 2. ì¹´í…Œê³ ë¦¬ë³„ ê³„ì‚°
    categories = df[category_col].unique()

    for category in categories:
        category_df = df[df[category_col] == category].copy()
        if len(category_df) > 0:
            cat_cum, cat_daily = calculate_delta_neutral_returns(category_df)
            all_results[category] = {
                'cumulative': cat_cum,
                'daily': cat_daily,
                'benchmark': benchmark_results[category],
                'metrics': calculate_performance_metrics_with_benchmark(cat_daily, benchmark_results[category])
            }

    return all_results


def calculate_delta_neutral_returns(df):
    """
    ë¸íƒ€-ë‰´íŠ¸ëŸ´ ë°©ì‹ìœ¼ë¡œ ëˆ„ì  ìˆ˜ìµë¥  ê³„ì‚°
    """
    # current_dateë¥¼ datetimeìœ¼ë¡œ ë³€í™˜
    df['current_date'] = pd.to_datetime(df['current_date'])

    # ê° ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”
    grouped = df.groupby('current_date')

    # ì¼ë³„ ìˆ˜ìµë¥  ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    daily_results = []

    for date, group in grouped:
        # ë¡± í¬ì§€ì…˜ê³¼ ìˆ í¬ì§€ì…˜ ë¶„ë¦¬
        long_positions = group[group['long_return'] != 0]
        short_positions = group[group['short_return'] != 0]

        # ë¡±ê³¼ ìˆ ì¢…ëª© ìˆ˜
        n_long = len(long_positions)
        n_short = len(short_positions)

        # ë¸íƒ€-ë‰´íŠ¸ëŸ´ ê°€ì¤‘ì¹˜ ê³„ì‚°
        if n_long > 0:
            long_weight = 0.5 / n_long
            weighted_long_return = (
                long_positions['long_return'] * long_weight).sum()
        else:
            weighted_long_return = 0

        if n_short > 0:
            short_weight = 0.5 / n_short
            weighted_short_return = (
                short_positions['short_return'] * short_weight).sum()
        else:
            weighted_short_return = 0

        # ë¡±ìˆ í•©ì‚° ìˆ˜ìµë¥ 
        long_short_return = weighted_long_return + weighted_short_return

        daily_results.append({
            'current_date': date,
            'long_return': weighted_long_return,
            'short_return': weighted_short_return,
            'long_short_return': long_short_return,
            'n_long': n_long,
            'n_short': n_short,
            'n_total': n_long + n_short
        })

    # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
    daily_returns = pd.DataFrame(daily_results).set_index('current_date')

    # ëˆ„ì  ìˆ˜ìµë¥  ê³„ì‚°
    cumulative_returns = pd.DataFrame(index=daily_returns.index)
    cumulative_returns['Long'] = (1 + daily_returns['long_return']).cumprod()
    cumulative_returns['Short'] = (1 + daily_returns['short_return']).cumprod()
    cumulative_returns['Long+Short'] = (1 +
                                        daily_returns['long_short_return']).cumprod()

    return cumulative_returns, daily_returns


def calculate_performance_metrics_with_benchmark(daily_returns, benchmark_data):
    """
    ë²¤ì¹˜ë§ˆí¬ë¥¼ í¬í•¨í•œ ì„±ê³¼ ì§€í‘œ ê³„ì‚°
    """
    metrics = {}

    # ì‹¤ì œ ê±°ë˜ì¼ ìˆ˜ ê³„ì‚°
    start_date = daily_returns.index.min()
    end_date = daily_returns.index.max()
    total_days = (end_date - start_date).days
    trading_days = len(daily_returns)

    # ì—°ê°„ ê±°ë˜ì¼ ìˆ˜ ì¶”ì •
    annual_trading_days = trading_days * 365 / total_days if total_days > 0 else 252

    # ë²¤ì¹˜ë§ˆí¬ ìˆ˜ìµë¥  (ë‚ ì§œ ë§¤ì¹­)
    benchmark_returns = benchmark_data['benchmark_return'].reindex(
        daily_returns.index).fillna(0)

    for column in ['long_return', 'short_return', 'long_short_return']:
        returns = daily_returns[column]

        # ê¸°ë³¸ ì§€í‘œë“¤
        annual_return = (1 + returns.mean()) ** annual_trading_days - 1
        annual_vol = returns.std() * np.sqrt(annual_trading_days)
        sharpe_ratio = annual_return / annual_vol if annual_vol != 0 else 0

        # ìµœëŒ€ ë‚™í­
        cumulative = (1 + returns).cumprod()
        running_max = cumulative.cummax()
        drawdown = (cumulative - running_max) / running_max
        max_drawdown = drawdown.min()

        # ëˆ„ì  ìˆ˜ìµë¥ 
        total_return = (1 + returns).prod() - 1

        # ë²¤ì¹˜ë§ˆí¬ ëŒ€ë¹„ ì§€í‘œë“¤
        excess_returns = returns - benchmark_returns

        # ì•ŒíŒŒ, ë² íƒ€ (CAPM)
        if len(returns) > 1 and benchmark_returns.std() != 0:
            try:
                beta, alpha_intercept, r_value, p_value, std_err = stats.linregress(
                    benchmark_returns, returns)
                alpha = alpha_intercept * annual_trading_days
            except:
                beta, alpha, r_value = 0, 0, 0
        else:
            beta, alpha, r_value = 0, 0, 0

        # ì •ë³´ë¹„ìœ¨ (Information Ratio)
        tracking_error = excess_returns.std() * np.sqrt(annual_trading_days)
        information_ratio = (annual_return - benchmark_returns.mean() *
                             annual_trading_days) / tracking_error if tracking_error != 0 else 0

        # ì†Œë¥´í‹°ë…¸ ë¹„ìœ¨ (Sortino Ratio)
        downside_returns = returns[returns < 0]
        downside_vol = downside_returns.std(
        ) * np.sqrt(annual_trading_days) if len(downside_returns) > 0 else 0
        sortino_ratio = annual_return / downside_vol if downside_vol != 0 else 0

        # ì¹¼ë§ˆ ë¹„ìœ¨ (Calmar Ratio)
        calmar_ratio = annual_return / \
            abs(max_drawdown) if max_drawdown != 0 else 0

        # VaR & CVaR (95% ì‹ ë¢°ìˆ˜ì¤€)
        var_95 = np.percentile(returns, 5)
        cvar_95 = returns[returns <= var_95].mean() if len(
            returns[returns <= var_95]) > 0 else var_95

        # í•˜í–¥ ë³€ë™ì„± (ì—°ìœ¨í™”)
        downside_volatility = downside_vol

        metrics[column] = {
            'total_return': total_return,
            'annual_return': annual_return,
            'annual_vol': annual_vol,
            'sharpe_ratio': sharpe_ratio,
            'sortino_ratio': sortino_ratio,
            'calmar_ratio': calmar_ratio,
            'max_drawdown': max_drawdown,
            'beta': beta,
            'alpha': alpha,
            'information_ratio': information_ratio,
            'tracking_error': tracking_error,
            'var_95': var_95,
            'cvar_95': cvar_95,
            'downside_volatility': downside_volatility,
            'correlation': r_value
        }

    # ë²¤ì¹˜ë§ˆí¬ ì§€í‘œë„ ì¶”ê°€
    benchmark_annual_return = (
        1 + benchmark_returns.mean()) ** annual_trading_days - 1
    benchmark_annual_vol = benchmark_returns.std() * np.sqrt(annual_trading_days)
    benchmark_sharpe = benchmark_annual_return / \
        benchmark_annual_vol if benchmark_annual_vol != 0 else 0
    benchmark_cumulative = (1 + benchmark_returns).cumprod()
    benchmark_running_max = benchmark_cumulative.cummax()
    benchmark_drawdown = (benchmark_cumulative -
                          benchmark_running_max) / benchmark_running_max
    benchmark_max_drawdown = benchmark_drawdown.min()
    benchmark_total_return = (1 + benchmark_returns).prod() - 1

    metrics['benchmark'] = {
        'total_return': benchmark_total_return,
        'annual_return': benchmark_annual_return,
        'annual_vol': benchmark_annual_vol,
        'sharpe_ratio': benchmark_sharpe,
        'max_drawdown': benchmark_max_drawdown,
        'var_95': np.percentile(benchmark_returns, 5),
        'cvar_95': benchmark_returns[benchmark_returns <= np.percentile(benchmark_returns, 5)].mean()
    }

    return metrics


def create_comprehensive_summary_table(all_results):
    """
    ë²¤ì¹˜ë§ˆí¬ë¥¼ í¬í•¨í•œ ì¢…í•© ìš”ì•½ í…Œì´ë¸” ìƒì„± (Long, Short, Long+Short, Benchmark)
    """
    summary_data = []

    for category, data in all_results.items():
        if 'metrics' in data and 'daily' in data:
            long_metrics = data['metrics']['long_return']
            short_metrics = data['metrics']['short_return']
            longshort_metrics = data['metrics']['long_short_return']
            benchmark_metrics = data['metrics']['benchmark']
            daily = data['daily']

            # ì¼í‰ê·  ê±°ë˜ ì¢…ëª© ìˆ˜ (ì‹¤ì œ í¬ì§€ì…˜ì„ ê°€ì§„ ì¢…ëª©)
            avg_trading_stocks = daily['n_total'].mean()

            # ì¼í‰ê·  ì „ì²´ ì¢…ëª© ìˆ˜ (ë²¤ì¹˜ë§ˆí¬ì— í¬í•¨ëœ ëª¨ë“  ì¢…ëª©)
            avg_total_stocks = data['benchmark']['n_stocks'].mean()

            summary_data.append({
                'ì „ëµ ìœ í˜•': category,
                'ìµœì¢… ëˆ„ì ìˆ˜ìµë¥ ': longshort_metrics['total_return'],
                'ì—°ìœ¨í™” ìˆ˜ìµë¥ ': longshort_metrics['annual_return'],
                'ë²¤ì¹˜ë§ˆí¬ ëŒ€ë¹„ ì´ˆê³¼ìˆ˜ìµë¥ ': longshort_metrics['annual_return'] - benchmark_metrics['annual_return'],
                'ì¼í‰ê·  ê±°ë˜ ì¢…ëª© ìˆ˜': avg_trading_stocks,
                'ì¼í‰ê·  ì „ì²´ ì¢…ëª© ìˆ˜': avg_total_stocks,
                'ì¼ í‘œì¤€í¸ì°¨': daily['long_short_return'].std(),
                'ì¼ ë¶„ì‚°': daily['long_short_return'].var(),
                'ì™œë„': daily['long_short_return'].skew(),
                'ì²¨ë„': daily['long_short_return'].kurtosis(),
                'ìµœëŒ€ ìˆ˜ìµ': daily['long_short_return'].max(),
                'ìµœì†Œ ìˆ˜ìµ': daily['long_short_return'].min()
            })

    summary_df = pd.DataFrame(summary_data)

    # ì „ì²´ë¥¼ ë§¨ ìœ„ë¡œ
    if 'ì „ì²´' in summary_df['ì „ëµ ìœ í˜•'].values:
        ì „ì²´_row = summary_df[summary_df['ì „ëµ ìœ í˜•'] == 'ì „ì²´']
        other_rows = summary_df[summary_df['ì „ëµ ìœ í˜•'] !=
                                'ì „ì²´'].sort_values('ì¼í‰ê·  ê±°ë˜ ì¢…ëª© ìˆ˜', ascending=False)
        summary_df = pd.concat([ì „ì²´_row, other_rows])

    return summary_df


def create_four_strategy_comparison_table(all_results):
    """
    ê° ì¹´í…Œê³ ë¦¬ë³„ Long Only, Short Only, Long+Short, Benchmark ë¹„êµ í…Œì´ë¸”
    """
    comparison_data = []

    for category, data in all_results.items():
        if 'metrics' in data:
            long_metrics = data['metrics']['long_return']
            short_metrics = data['metrics']['short_return']
            longshort_metrics = data['metrics']['long_short_return']
            benchmark_metrics = data['metrics']['benchmark']

            comparison_data.append({
                'ì „ëµ ìœ í˜•': category,
                'Long (50%)': long_metrics['total_return'],
                'Short (50%)': short_metrics['total_return'],
                'Long+Short (Delta-Neutral)': longshort_metrics['total_return'],
                'Market Average Benchmark': benchmark_metrics['total_return']
            })

    comparison_df = pd.DataFrame(comparison_data)

    # ì „ì²´ë¥¼ ë§¨ ìœ„ë¡œ
    if 'ì „ì²´' in comparison_df['ì „ëµ ìœ í˜•'].values:
        ì „ì²´_row = comparison_df[comparison_df['ì „ëµ ìœ í˜•'] == 'ì „ì²´']
        other_rows = comparison_df[comparison_df['ì „ëµ ìœ í˜•'] != 'ì „ì²´'].sort_values(
            'Long+Short (Delta-Neutral)', ascending=False)
        comparison_df = pd.concat([ì „ì²´_row, other_rows])

    return comparison_df


def create_risk_adjusted_metrics_table(all_results):
    """
    ìœ„í—˜ì¡°ì • ì§€í‘œ í…Œì´ë¸” ìƒì„±
    """
    risk_data = []

    for category, data in all_results.items():
        if 'metrics' in data:
            long_metrics = data['metrics']['long_return']
            short_metrics = data['metrics']['short_return']
            longshort_metrics = data['metrics']['long_short_return']
            benchmark_metrics = data['metrics']['benchmark']

            risk_data.append({
                'ì „ëµ ìœ í˜•': category,
                'ìƒ¤í”„ ë¹„ìœ¨': longshort_metrics['sharpe_ratio'],
                'ì†Œë¥´í‹°ë…¸ ë¹„ìœ¨': longshort_metrics['sortino_ratio'],
                'ì¹¼ë§ˆ ë¹„ìœ¨': longshort_metrics['calmar_ratio'],
                'VaR (95%)': longshort_metrics['var_95'],
                'CVaR (95%)': longshort_metrics['cvar_95'],
                'í•˜í–¥ ë³€ë™ì„±(ì—°ìœ¨í™”)': longshort_metrics['downside_volatility']
            })

    risk_df = pd.DataFrame(risk_data)

    # ì „ì²´ë¥¼ ë§¨ ìœ„ë¡œ
    if 'ì „ì²´' in risk_df['ì „ëµ ìœ í˜•'].values:
        ì „ì²´_row = risk_df[risk_df['ì „ëµ ìœ í˜•'] == 'ì „ì²´']
        other_rows = risk_df[risk_df['ì „ëµ ìœ í˜•'] !=
                             'ì „ì²´'].sort_values('ìƒ¤í”„ ë¹„ìœ¨', ascending=False)
        risk_df = pd.concat([ì „ì²´_row, other_rows])

    return risk_df


def plot_comprehensive_analysis(all_results, save_dir='comprehensive_analysis'):
    """
    ì¢…í•© ë¶„ì„ ê·¸ë˜í”„ ìƒì„± (Long, Short, Long+Short, Market Average Benchmark)
    """
    os.makedirs(save_dir, exist_ok=True)

    # 1. ì „ì²´ ì¹´í…Œê³ ë¦¬ë³„ Long+Short vs Market Average Benchmark ë¹„êµ
    fig, ax = plt.subplots(figsize=(15, 10))

    for category, data in all_results.items():
        if 'cumulative' in data and 'benchmark' in data:
            # í¬íŠ¸í´ë¦¬ì˜¤ Long+Short ëˆ„ì  ìˆ˜ìµë¥ 
            ax.plot(data['cumulative'].index,
                    data['cumulative']['Long+Short'],
                    label=f'{category} (Delta-Neutral)',
                    linewidth=3 if category == 'ì „ì²´' else 2,
                    color='green')

            # ë²¤ì¹˜ë§ˆí¬ ëˆ„ì  ìˆ˜ìµë¥ 
            ax.plot(data['benchmark'].index,
                    data['benchmark']['cumulative_return'],
                    label=f'{category} (Market Average)',
                    linewidth=2,
                    linestyle='--',
                    color='gray',
                    alpha=0.8)

    ax.set_title('ì¹´í…Œê³ ë¦¬ë³„ Delta-Neutral vs Market Average Benchmark ëˆ„ì  ìˆ˜ìµë¥  ë¹„êµ',
                 fontsize=16, fontweight='bold')
    ax.set_xlabel('Date', fontsize=12)
    ax.set_ylabel('Cumulative Return', fontsize=12)
    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    ax.grid(True, alpha=0.3)
    ax.yaxis.set_major_formatter(
        plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y-1)))

    plt.tight_layout()
    fig.savefig(f'{save_dir}/delta_neutral_vs_market_benchmark.png',
                dpi=300, bbox_inches='tight')
    plt.close()

    # 2. ì¹´í…Œê³ ë¦¬ë³„ 4ê°€ì§€ ì „ëµ ë¹„êµ (Long, Short, Long+Short, Market Average Benchmark)
    for category, data in all_results.items():
        if 'cumulative' in data and 'benchmark' in data:
            fig, ax = plt.subplots(figsize=(14, 10))

            # Long, Short, Long+Short ì „ëµ
            ax.plot(data['cumulative'].index, data['cumulative']['Long'],
                    label='Long (50%)', linewidth=2.5, color='blue')
            ax.plot(data['cumulative'].index, data['cumulative']['Short'],
                    label='Short (50%)', linewidth=2.5, color='red')
            ax.plot(data['cumulative'].index, data['cumulative']['Long+Short'],
                    label='Long+Short (Delta-Neutral)', linewidth=2.5, color='green')

            # ë²¤ì¹˜ë§ˆí¬
            ax.plot(data['benchmark'].index, data['benchmark']['cumulative_return'],
                    label='Market Average Benchmark', linewidth=2.5, color='gray', linestyle='--')

            ax.set_title(
                f'{category}: Delta-Neutral Portfolio vs Market Average Benchmark', fontsize=15, fontweight='bold')
            ax.set_xlabel('Date', fontsize=12)
            ax.set_ylabel('Cumulative Return', fontsize=12)
            ax.legend(loc='best')
            ax.grid(True, alpha=0.3)
            ax.yaxis.set_major_formatter(
                plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y-1)))

            plt.tight_layout()
            safe_filename = category.replace(' ', '_').replace('/', '_')
            fig.savefig(
                f'{save_dir}/delta_neutral_{safe_filename}.png', dpi=300, bbox_inches='tight')
            plt.close()

    print(f"ğŸ“Š ì¢…í•© ë¶„ì„ ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ â†’ '{save_dir}' í´ë”")


def print_formatted_table_enhanced(df, title):
    """í¬ë§·íŒ…ëœ í…Œì´ë¸” ì¶œë ¥ (í–¥ìƒëœ ë²„ì „)"""
    print(f"\n{'='*100}")
    print(f"{title:^100}")
    print('='*100)

    # ìˆ«ì í¬ë§·íŒ…
    df_formatted = df.copy()
    for col in df_formatted.columns:
        if col in ['ì¼í‰ê·  ê±°ë˜ ì¢…ëª© ìˆ˜', 'ì¼í‰ê·  ì „ì²´ ì¢…ëª© ìˆ˜']:
            df_formatted[col] = df_formatted[col].apply(
                lambda x: f"{x:,.1f}" if pd.notna(x) else '')
        elif col in ['ìµœì¢… ëˆ„ì ìˆ˜ìµë¥ ', 'ì—°ìœ¨í™” ìˆ˜ìµë¥ ', 'ë²¤ì¹˜ë§ˆí¬ ëŒ€ë¹„ ì´ˆê³¼ìˆ˜ìµë¥ ',
                     'Long (50%)', 'Short (50%)', 'Long+Short (Delta-Neutral)', 'Market Average Benchmark']:
            df_formatted[col] = df_formatted[col].apply(
                lambda x: f"{x:.2%}" if isinstance(x, (int, float)) else x)
        elif col in ['ì¼ í‘œì¤€í¸ì°¨', 'ì¼ ë¶„ì‚°', 'ì™œë„', 'ì²¨ë„', 'ìµœëŒ€ ìˆ˜ìµ', 'ìµœì†Œ ìˆ˜ìµ',
                     'VaR (95%)', 'CVaR (95%)', 'í•˜í–¥ ë³€ë™ì„±(ì—°ìœ¨í™”)']:
            df_formatted[col] = df_formatted[col].apply(
                lambda x: f"{x:.4f}" if isinstance(x, (int, float)) else x)
        elif col in ['ìƒ¤í”„ ë¹„ìœ¨', 'ì†Œë¥´í‹°ë…¸ ë¹„ìœ¨', 'ì¹¼ë§ˆ ë¹„ìœ¨']:
            df_formatted[col] = df_formatted[col].apply(
                lambda x: f"{x:.3f}" if isinstance(x, (int, float)) else x)

    print(df_formatted.to_string(index=False))
    print('='*100)


# ë©”ì¸ ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    # 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    df = pd.read_csv(
        '/Users/imdonghyeon/Desktop/Quantlab/final_ìˆ˜ì •/news_with_sector.csv')

    # ë°ì´í„° íƒ€ì… ë³€í™˜
    df['long_return'] = pd.to_numeric(
        df['long_return'], errors='coerce').fillna(0)
    df['short_return'] = pd.to_numeric(
        df['short_return'], errors='coerce').fillna(0)

    # 2. ê¸°ë³¸ ì •ë³´ ì¶œë ¥
    print("ğŸ“Š ë°ì´í„° ê¸°ë³¸ ì •ë³´")
    print("-" * 50)
    print(f"ë°ì´í„° shape: {df.shape}")
    print(f"ê¸°ê°„: {df['current_date'].min()} ~ {df['current_date'].max()}")
    print(f"ê·œëª¨êµ¬ë¶„ ì¢…ë¥˜: {df['ê·œëª¨êµ¬ë¶„'].nunique()}ê°œ")
    print(f"ê·œëª¨êµ¬ë¶„ ëª©ë¡: {sorted(df['ê·œëª¨êµ¬ë¶„'].dropna().unique())}")

    # 3. ë²¤ì¹˜ë§ˆí¬ë¥¼ í¬í•¨í•œ ì¹´í…Œê³ ë¦¬ë³„ ë¸íƒ€-ë‰´íŠ¸ëŸ´ ë¶„ì„
    all_results = calculate_delta_neutral_by_category_with_benchmark(df)

    # 4. Long Only, Short Only, Long+Short, Market Average Benchmark ë¹„êµ í…Œì´ë¸”
    four_strategy_df = create_four_strategy_comparison_table(all_results)
    print_formatted_table_enhanced(
        four_strategy_df, "Delta-Neutral Portfolio vs Market Average Benchmark ìµœì¢… ëˆ„ì ìˆ˜ìµë¥  ë¹„êµ")

    # 5. ì¢…í•© ìš”ì•½ í…Œì´ë¸” (Statistical Measures)
    summary_df = create_comprehensive_summary_table(all_results)
    print_formatted_table_enhanced(summary_df, "Statistical Measures")

    # 6. ìœ„í—˜ì¡°ì • ì§€í‘œ í…Œì´ë¸” (Risk-Adjusted Metrics)
    risk_df = create_risk_adjusted_metrics_table(all_results)
    print_formatted_table_enhanced(risk_df, "Risk-Adjusted Metrics")

    # 7. ì¢…í•© ë¶„ì„ ê·¸ë˜í”„ ìƒì„±
    plot_comprehensive_analysis(all_results)

    # 8. ê²°ê³¼ ì €ì¥
    four_strategy_df.to_csv(
        'delta_neutral_strategy_comparison.csv', encoding='utf-8-sig', index=False)
    summary_df.to_csv('statistical_measures.csv',
                      encoding='utf-8-sig', index=False)
    risk_df.to_csv('risk_adjusted_metrics.csv',
                   encoding='utf-8-sig', index=False)

    # 9. ê° ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ì„±ê³¼ ë¶„ì„
    print("\n" + "="*100)
    print("ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ì„±ê³¼ ë¶„ì„")
    print("="*100)

    for category, data in all_results.items():
        if 'metrics' in data:
            print(f"\nğŸ“Š {category} ì „ëµ ë¶„ì„:")
            print("-" * 50)

            long_metrics = data['metrics']['long_return']
            short_metrics = data['metrics']['short_return']
            longshort_metrics = data['metrics']['long_short_return']
            benchmark_metrics = data['metrics']['benchmark']

            print(
                f"Long (50%)         ìˆ˜ìµë¥ : {long_metrics['total_return']:.2%}")
            print(
                f"Short (50%)        ìˆ˜ìµë¥ : {short_metrics['total_return']:.2%}")
            print(
                f"Delta-Neutral      ìˆ˜ìµë¥ : {longshort_metrics['total_return']:.2%}")
            print(
                f"Market Average Benchmark: {benchmark_metrics['total_return']:.2%}")
            print(
                f"ì´ˆê³¼ ìˆ˜ìµë¥  (vs Benchmark): {longshort_metrics['total_return'] - benchmark_metrics['total_return']:.2%}")
            print(f"ìƒ¤í”„ ë¹„ìœ¨: {longshort_metrics['sharpe_ratio']:.3f}")
            print(f"ìµœëŒ€ ë‚™í­: {longshort_metrics['max_drawdown']:.2%}")

    print("\nâœ… Delta-Neutral vs Market Average Benchmark ë¶„ì„ ì™„ë£Œ!")
    print("ğŸ“ ìƒì„±ëœ íŒŒì¼:")
    print("  - delta_neutral_strategy_comparison.csv")
    print("  - statistical_measures.csv")
    print("  - risk_adjusted_metrics.csv")
    print("  - comprehensive_analysis/ (ê·¸ë˜í”„ í´ë”)")
